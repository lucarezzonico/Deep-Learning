{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mini_Project_1_colab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WojVNR211P27","executionInfo":{"status":"ok","timestamp":1653674311663,"user_tz":-120,"elapsed":16688,"user":{"displayName":"luca rezzonico","userId":"12279849641516158473"}},"outputId":"6956e956-2217-4aa2-8b48-df117203233b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**net.py**"],"metadata":{"id":"F2FLRoAe1BQ1"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","\n","class Net(nn.Module):\n","    def __init__(self, nb_input=3, nb_output=3):\n","        # initialize deep-learning network\n","        super(Net, self).__init__()\n","\n","        # Blocks: enc_conv0, enc_conv1, pool1\n","        self.group1 = nn.Sequential(\n","            nn.Conv2d(in_channels=nb_input, out_channels=48, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # Blocks: enc_conv(i), pool(i); i=2..5\n","        self.group2 = nn.Sequential(\n","            nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # Blocks: enc_conv6, upsample5\n","        self.group3 = nn.Sequential(\n","            nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(in_channels=48, out_channels=48, kernel_size=3, stride=2, padding=1, output_padding=1, dilation=1))\n","            # nn.Upsample(scale_factor=2, mode='nearest'))\n","\n","        # Blocks: dec_conv5a, dec_conv5b, upsample4\n","        self.group4 = nn.Sequential(\n","            nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(in_channels=96, out_channels=96, kernel_size=3, stride=2, padding=1, output_padding=1, dilation=1))\n","            # nn.Upsample(scale_factor=2, mode='nearest'))\n","\n","        # Blocks: dec_deconv(i)a, dec_deconv(i)b, upsample(i-1); i=4..2\n","        self.group5 = nn.Sequential(\n","            nn.Conv2d(in_channels=144, out_channels=96, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(in_channels=96, out_channels=96, kernel_size=3, stride=2, padding=1, output_padding=1, dilation=1))\n","            # nn.Upsample(scale_factor=2, mode='nearest'))\n","\n","        # Blocks: dec_conv1a, dec_conv1b, dec_conv1c\n","        self.group6 = nn.Sequential(\n","            nn.Conv2d(in_channels=96 + nb_input, out_channels=64, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels=32, out_channels=nb_output, kernel_size=3, stride=1, padding=1, dilation=1),\n","            nn.LeakyReLU(negative_slope=0.1))\n","    \n","\n","    def forward(self, input):\n","\n","        # Encoder\n","        pool1 = self.group1(input)\n","        pool2 = self.group2(pool1)\n","        pool3 = self.group2(pool2)\n","        pool4 = self.group2(pool3)\n","        pool5 = self.group2(pool4)\n","\n","        # Decoder\n","        upsample5 = self.group3(pool5)\n","        concat5 = torch.cat((upsample5, pool4), dim=1) # skip connection\n","        upsample4 = self.group4(concat5)\n","        concat4 = torch.cat((upsample4, pool3), dim=1) # skip connection\n","        upsample3 = self.group5(concat4)\n","        concat3 = torch.cat((upsample3, pool2), dim=1) # skip connection\n","        upsample2 = self.group5(concat3)\n","        concat2 = torch.cat((upsample2, pool1), dim=1) # skip connection\n","        upsample1 = self.group5(concat2)\n","        concat1 = torch.cat((upsample1, input), dim=1) # skip connection\n","        output = self.group6(concat1)\n","\n","        # Final activation\n","        return output\n","\n","class Net2(nn.Module):\n","    def __init__(self, nb_input=3, nb_output=3):\n","        # initialize deep-learning network\n","        super(Net2, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            # encoder\n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=32, out_channels=8, kernel_size=4, stride=1, padding=0, dilation=1),\n","            # decoder\n","            nn.ConvTranspose2d(in_channels=8, out_channels=32, kernel_size=4, stride=1, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=3, stride=2, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=4, stride=2, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=0, dilation=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(in_channels=32, out_channels=3, kernel_size=5, stride=1, padding=0, dilation=1)\n","        )\n","\n","    def forward(self, input):\n","        return self.model(input)\n","\n","class Net3(nn.Module):\n","    def __init__(self, nb_input=3, nb_output=3):\n","        # initialize deep-learning network\n","        super(Net3, self).__init__()\n","\n","        self.model = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=2, stride=2, padding=0),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=2, stride=2, padding=0),\n","            nn.ReLU(),\n","            nn.UpsamplingNearest2d(scale_factor=2),\n","            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=2, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.UpsamplingNearest2d(scale_factor=2),\n","            nn.Conv2d(in_channels=128, out_channels=3, kernel_size=3, stride=1, padding=0),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.model(input)\n"],"metadata":{"id":"-3zwiDiM0VI4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**model.py**"],"metadata":{"id":"Ww7ciCEA05FI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJMycXwf0K3t"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch import optim\n","# from Miniproject_1.other.net import *\n","# model.py will be imported by the testing pipeline\n","\n","class Model():\n","    def __init__(self, net='Net', lr=1e-4, optimizer='SGD', criterion='MSE', scheduler_gamma=0.8) -> None:\n","        ## instantiate model + optimizer + loss function + any other stuff you need\n","\n","        if net == 'Net':\n","            self.model = Net()\n","        if net == 'Net2':\n","            self.model = Net2()\n","        if net == 'Net3':\n","            self.model = Net3()\n","\n","        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        print(self.device)\n","        self.model.to(self.device)\n","\n","        self.learning_rate = lr\n","\n","        if criterion == 'MSE':\n","            self.criterion = nn.MSELoss()\n","        if criterion == 'CrossEntropyLoss':\n","            self.criterion = nn.CrossEntropyLoss()\n","\n","        if optimizer == 'SGD':\n","            self.optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate)\n","        if optimizer == 'Adam':\n","            self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n","        if optimizer == 'Adagrad':\n","            self.optimizer = optim.Adagrad(self.model.parameters(), lr=self.learning_rate)\n","        if optimizer == 'Adadelta':\n","            self.optimizer = optim.Adadelta(self.model.parameters(), lr=self.learning_rate)\n","\n","        # self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=1, gamma=scheduler_gamma)\n","\n","    def save_model(self, path='Miniproject_1/bestmodel.pth') -> None:\n","        ## This saves the parameters of the model into bestmodel.pth\n","        torch.save(self.model.state_dict(), path)\n","        # print('model saved to bestmodel.pth')\n","\n","    def load_pretrained_model(self, path='Miniproject_1/bestmodel.pth') -> None:\n","        ## This loads the parameters saved in bestmodel.pth into the model\n","        m_state_dict = torch.load(path)\n","        self.model.load_state_dict(m_state_dict)\n","        # print('model loaded')\n","\n","    def train(self, train_input, train_target, num_epochs=7, mini_batch_size=4, lambda_l2=0) -> None:\n","        #: train_input : tensor of size (N, C, H, W) containing a noisy version of the images.\n","        #: train_target : tensor of size (N, C, H, W) containing another noisy version of the same images, which only differs from the input by their noise.\n","\n","        train_input, train_target = train_input.to(self.device), train_target.to(self.device)\n","\n","        train_input = train_input.float().div(255)\n","        train_target = train_target.float().div(255)\n","\n","        for e in range(num_epochs):\n","            for b in range(0, train_input.size(dim=0), mini_batch_size):\n","                output = self.model(train_input.narrow(dim=0, start=b, length=mini_batch_size))  # takes time\n","                loss = self.criterion(output, train_target.narrow(dim=0, start=b, length=mini_batch_size))\n","                self.optimizer.zero_grad()\n","\n","                # L2 penalty term (to avoid overfitting the training data for an increasing number of epochs)\n","                for p in self.model.parameters():\n","                    loss += lambda_l2 * p.pow(2).sum()\n","\n","                loss.backward()  # takes time\n","                self.optimizer.step()\n","                \n","            print('epoch {:d}/{:d}'.format(e + 1, num_epochs), 'training loss = {:.5f}'.format(loss))\n","            # self.scheduler.step()  # decrease learning rate\n","\n","    def predict(self, test_input) -> torch.Tensor:\n","        #: test_input : tensor of size (N1 , C, H, W) that has to be denoised by the trained or the loaded network.\n","        #: returns a tensor of the size (N1 , C, H, W)\n","\n","        test_input = test_input.to(self.device)\n","\n","        test_input = test_input.float().div(255)\n","        predicted_output = self.model(test_input)\n","        predicted_output = predicted_output.mul(255).to(torch.uint8)\n","\n","        return predicted_output\n"]},{"cell_type":"markdown","source":["**run_miniproject_1.py**"],"metadata":{"id":"m3dUuU3L0pml"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import (DataLoader,)  # Gives easier dataset managment and creates mini batches\n","import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n","import matplotlib.pyplot as plt\n","\n","# from Miniproject_1.model import Model\n","\n","path_to_project = '/content/drive/MyDrive/Colab Notebooks/'\n","\n","# noisy_imgs_train_1, noisy_imgs_train_2 = torch.load('miniproject_dataset/train_data.pkl')\n","# noisy_imgs_valid, clean_imgs_valid = torch.load('miniproject_dataset/val_data.pkl')\n","noisy_imgs_train_1, noisy_imgs_train_2 = torch.load(open(path_to_project + 'miniproject_dataset/train_data.pkl', 'rb'))\n","noisy_imgs_valid, clean_imgs_valid = torch.load(open(path_to_project + '/miniproject_dataset/val_data.pkl', 'rb'))\n","\n","print('noisy_imgs_train_1', noisy_imgs_train_1.size(), 'noisy_imgs_train_2', noisy_imgs_train_2.size())\n","print('noisy_imgs_valid', noisy_imgs_valid.size(), 'clean_imgs_valid', clean_imgs_valid.size())\n","\n","\n","def compute_psnr_mean(x, y):\n","    assert x.shape == y.shape and x.ndim == 4\n","    return - 10 * torch.log10(((x-y) ** 2).mean((1,2,3))).mean()\n","\n","def compute_psnr_std(x, y):\n","    assert x.shape == y.shape and x.ndim == 4\n","    return - 10 * torch.log10(((x-y) ** 2).mean((1,2,3))).std()\n","\n","def plot_images(*args, titles):\n","    for i in range(args[0].size(dim=0)): # number images to plot for each dataset\n","        if len(args) > 1: _, axes = plt.subplots(1, len(args))\n","        for img, idx in zip(args, range(len(args))): # number datasets to plot\n","            if len(args) > 1:\n","                axes[idx].imshow(img[i,:,:,:].permute((1, 2, 0)))\n","                axes[idx].set_title(titles[idx])\n","            else:\n","                plt.imshow(img[i, :, :, :].permute((1, 2, 0)))\n","                plt.title(titles[idx])\n","        plt.show()\n","\n","# plot_images(noisy_imgs_train_1[0:4, :, :, :], noisy_imgs_train_2[0:4, :, :, :], titles=['noisy_imgs_train_1','noisy_imgs_train_2'])\n","# plot_images(noisy_imgs_valid[0:4, :, :, :], clean_imgs_valid[0:4, :, :, :], titles=['noisy_imgs_valid','clean_imgs_valid'])\n","\n","# transform data\n","my_transforms = transforms.Compose(\n","    [   # Compose makes it possible to have many transforms\n","        # transforms.ToPILImage(),\n","        # transforms.Resize((36, 36)),  # Resizes (32,32) to (36,36)\n","        # transforms.RandomCrop((32, 32)),  # Takes a random (32,32) crop\n","        # transforms.ColorJitter(brightness=0.5),  # Change brightness of image\n","        # transforms.RandomRotation(degrees=45),  # Perhaps a random rotation from -45 to 45 degrees\n","        transforms.RandomHorizontalFlip(p=1),  # Flips the image horizontally with probability 0.5\n","        transforms.RandomVerticalFlip(p=1),  # Flips image vertically with probability 0.05\n","        # transforms.RandomGrayscale(p=0.2),  # Converts to grayscale with probability 0.2\n","        # transforms.ToTensor(),  # Finally converts PIL image to tensor so we can train w. pytorch\n","        # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Note: these values aren't optimal\n","    ]\n",")\n","\n","data_augmentation = False\n","augmented_train_data_upper_index = 50000\n","\n","if data_augmentation:\n","    transformed_imgs = my_transforms(torch.cat((noisy_imgs_train_1[0:augmented_train_data_upper_index, :, :, :], noisy_imgs_train_2[0:augmented_train_data_upper_index, :, :, :]), dim=0))\n","\n","    noisy_imgs_train_1 = torch.cat((noisy_imgs_train_1, transformed_imgs[0:int(len(transformed_imgs)/2)]), dim=0)\n","    noisy_imgs_train_2 = torch.cat((noisy_imgs_train_2, transformed_imgs[int(len(transformed_imgs)/2):int(len(transformed_imgs))]), dim=0)\n","\n","    # print(len(noisy_imgs_train_1), len(noisy_imgs_train_2))\n","    # plot_images(transformed_imgs, titles=['transformed_imgs'])\n","\n","################################################################################\n","\n","#subset of data\n","train_data_upper_index = 50000\n","train_input = noisy_imgs_train_1[0:train_data_upper_index, :, :, :]\n","train_target = noisy_imgs_train_2[0:train_data_upper_index, :, :, :]\n","test_input = noisy_imgs_valid[0:1000, :, :, :]\n","test_target = clean_imgs_valid[0:1000, :, :, :]\n","\n","\n","# model = Model(net='Net', lr=1e-1, optimizer='SGD', criterion='MSE', scheduler_gamma=1)\n","model = Model(net='Net', lr=5e-4, optimizer='Adam', criterion='MSE', scheduler_gamma=1)\n","# model = Model(net='Net', lr=1e-3, optimizer='Adagrad', criterion='MSE', scheduler_gamma=1)\n","# model = Model(net='Net', lr=5e-1, optimizer='Adadelta', criterion='MSE', scheduler_gamma=1)\n","\n","# model = Model(net='Net2', lr=1e-1, optimizer='SGD', criterion='MSE', scheduler_gamma=1)\n","# model = Model(net='Net2', lr=5e-4, optimizer='Adam', criterion='MSE', scheduler_gamma=1)\n","# model = Model(net='Net2', lr=1e-3, optimizer='Adagrad', criterion='MSE', scheduler_gamma=1)\n","# model = Model(net='Net2', lr=5e-1, optimizer='Adadelta', criterion='MSE', scheduler_gamma=1)\n","\n","# train\n","model.train(train_input, train_target, num_epochs=7, mini_batch_size=8, lambda_l2=0)\n","model.save_model(path_to_project + 'Miniproject_1/bestmodel.pth')\n","\n","# load model\n","model.load_pretrained_model(path_to_project + 'Miniproject_1/bestmodel.pth')\n","\n","# denoise input\n","denoised_test_input = model.predict(test_input).cpu()\n","\n","# PSNR\n","psnr_mean = float(compute_psnr_mean(denoised_test_input.float().div(255), test_target.float().div(255)))\n","psnr_std = abs(float(compute_psnr_std(denoised_test_input.float().div(255), test_target.float().div(255))))\n","print('mean psnr = {:.5f}'.format(psnr_mean),'dB', 'std psnr = {:.5f}'.format(psnr_std),'dB')\n","\n","\n","# plot denoised image\n","plot_images(test_input[0:4,:,:,:], denoised_test_input[0:4,:,:,:].detach(), test_target[0:4,:,:,:],\n","            titles=['test_input','denoised_test_input','test_target'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"5MjVUxSQ0luZ","executionInfo":{"status":"error","timestamp":1653676711223,"user_tz":-120,"elapsed":556,"user":{"displayName":"luca rezzonico","userId":"12279849641516158473"}},"outputId":"a345b75e-b2e3-4b0c-e0d6-7163e182bd31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["noisy_imgs_train_1 torch.Size([50000, 3, 32, 32]) noisy_imgs_train_2 torch.Size([50000, 3, 32, 32])\n","noisy_imgs_valid torch.Size([1000, 3, 32, 32]) clean_imgs_valid torch.Size([1000, 3, 32, 32])\n","cuda:0\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-1425e1e992d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_project\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Miniproject_1/bestmodel.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# denoise input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-dd88ad9adc2e>\u001b[0m in \u001b[0;36mload_pretrained_model\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m## This loads the parameters saved in bestmodel.pth into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mm_state_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m# print('model loaded')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1481\u001b[0m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1484\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m   1476\u001b[0m             \u001b[0mlocal_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             module._load_from_state_dict(\n\u001b[0;32m-> 1478\u001b[0;31m                 state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n\u001b[0m\u001b[1;32m   1479\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mextra_state_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m                     \u001b[0minput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"]}]}]}